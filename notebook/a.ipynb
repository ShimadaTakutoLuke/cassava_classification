{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alexnet', 'convnext_base', 'convnext_large', 'convnext_small', 'convnext_tiny', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'efficientnet_v2_l', 'efficientnet_v2_m', 'efficientnet_v2_s', 'get_model', 'get_model_builder', 'get_model_weights', 'get_weight', 'googlenet', 'inception_v3', 'list_models', 'maxvit_t', 'mnasnet0_5', 'mnasnet0_75', 'mnasnet1_0', 'mnasnet1_3', 'mobilenet_v2', 'mobilenet_v3_large', 'mobilenet_v3_small', 'regnet_x_16gf', 'regnet_x_1_6gf', 'regnet_x_32gf', 'regnet_x_3_2gf', 'regnet_x_400mf', 'regnet_x_800mf', 'regnet_x_8gf', 'regnet_y_128gf', 'regnet_y_16gf', 'regnet_y_1_6gf', 'regnet_y_32gf', 'regnet_y_3_2gf', 'regnet_y_400mf', 'regnet_y_800mf', 'regnet_y_8gf', 'resnet101', 'resnet152', 'resnet18', 'resnet34', 'resnet50', 'resnext101_32x8d', 'resnext101_64x4d', 'resnext50_32x4d', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'squeezenet1_0', 'squeezenet1_1', 'swin_b', 'swin_s', 'swin_t', 'swin_v2_b', 'swin_v2_s', 'swin_v2_t', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'vit_b_16', 'vit_b_32', 'vit_h_14', 'vit_l_16', 'vit_l_32', 'wide_resnet101_2', 'wide_resnet50_2']\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# 利用可能な事前学習済みモデル一覧を表示\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "                     if name.islower() and not name.startswith(\"__\")\n",
    "                     and callable(models.__dict__[name]))\n",
    "\n",
    "print(model_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import vit_b_16\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのディレクトリ設定\n",
    "data_dir = \"/home/dataset/leaf_dataset/train\"\n",
    "\n",
    "# データの前処理設定(学習時と検証時)\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset = datasets.ImageFolder(data_dir, transform=data_transforms)\n",
    "\n",
    "# 8:2でデータセットを分割\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "# データローダー設定\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "dataloaders = {\"train\": train_loader, \"val\": val_loader}\n",
    "\n",
    "# クラス数の取得\n",
    "class_names = dataset.classes\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 1.1709 Acc: 0.6206\n",
      "val Loss: 1.1347 Acc: 0.6123\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 1.0899 Acc: 0.6318\n",
      "val Loss: 1.0894 Acc: 0.6236\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 1.0292 Acc: 0.6399\n",
      "val Loss: 1.0116 Acc: 0.6387\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.9855 Acc: 0.6468\n",
      "val Loss: 0.9877 Acc: 0.6387\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.9447 Acc: 0.6540\n",
      "val Loss: 0.9345 Acc: 0.6486\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.9135 Acc: 0.6606\n",
      "val Loss: 0.9177 Acc: 0.6563\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.9098 Acc: 0.6649\n",
      "val Loss: 0.9129 Acc: 0.6571\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.8520 Acc: 0.6861\n",
      "val Loss: 0.8665 Acc: 0.6769\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.8369 Acc: 0.6903\n",
      "val Loss: 0.8355 Acc: 0.6874\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.8212 Acc: 0.6919\n",
      "val Loss: 0.8462 Acc: 0.6852\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.8225 Acc: 0.6954\n",
      "val Loss: 0.8406 Acc: 0.6885\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.8186 Acc: 0.6967\n",
      "val Loss: 0.8195 Acc: 0.6923\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.8064 Acc: 0.6990\n",
      "val Loss: 0.8329 Acc: 0.6904\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.7981 Acc: 0.7027\n",
      "val Loss: 0.8228 Acc: 0.6910\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.7923 Acc: 0.7077\n",
      "val Loss: 0.8172 Acc: 0.6934\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.7846 Acc: 0.7081\n",
      "val Loss: 0.8024 Acc: 0.6984\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.7876 Acc: 0.7073\n",
      "val Loss: 0.8099 Acc: 0.6948\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# GPUの確認\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Vision Transformerのロード\n",
    "model = vit_b_16(pretrained=True)\n",
    "\n",
    "# 出力層を葉の病害分類用に変更\n",
    "model.heads.head = nn.Linear(model.heads.head.in_features, num_classes)\n",
    "\n",
    "# モデルをGPUに転送\n",
    "model = model.to(device)\n",
    "\n",
    "# 損失関数とオプティマイザの設定\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 全てのパラメータを微分可能に設定\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 学習率の減少スケジューラ\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# 訓練用関数\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "        print(\"-\" * 10)\n",
    "        \n",
    "        # 各エポックでの学習フェーズと評価フェーズ\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else: \n",
    "                model.eval()\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # バッチごとのデータ処理\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # 勾配のリセット\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝播\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # 訓練フェーズではバックプロパゲーション + 最適化\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # ロスと正解数の統計\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == \"train\":\n",
    "                scheduler.step()\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "            \n",
    "            # 最良のモデルをコピー\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f\"Training complete in {time_elapsed // 68:.0f}m {time_elapsed % 60:.0f}s\")\n",
    "    print(f\"Best val Acc: {best_acc:.4f}\")\n",
    "    \n",
    "    # 最良モデルの重みをロード\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# モデルの訓練\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25)\n",
    "\n",
    "# 訓練後のモデル保存\n",
    "torch.save(model.state_dict(), \"leaf_disease_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
